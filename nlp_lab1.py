# -*- coding: utf-8 -*-
"""NLP_LAB1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d0NwgUQUu0CzXElPK3jAdyxDtCGqaSDK
"""

pip install nltk

import nltk
from nltk import FreqDist
from nltk.tokenize import word_tokenize

# Download NLTK resources (you only need to do this once)
nltk.download('punkt')

def word_frequency(paragraph):
    # Tokenize the paragraph into words
    words = word_tokenize(paragraph)

    # Calculate the frequency distribution of words
    freq_dist = FreqDist(words)

    # Display the word frequency
    print("Word\t\tFrequency")
    print("------------------------")
    for word, frequency in freq_dist.items():
        print(f"{word}\t\t{frequency}")

# Your paragraph
paragraph = "NLP NLTK CODE IN PYTHON is a powerful combination for natural language processing tasks."

# Call the function to display word frequency
word_frequency(paragraph)

pip install requests beautifulsoup4 nltk

import requests
from bs4 import BeautifulSoup
from nltk.tokenize import word_tokenize, regexp_tokenize

# Function to extract tokens, expressions, words, and numbers from a webpage
def extract_content_from_webpage(url):
    # Send an HTTP request to the URL
    response = requests.get(url)

    # Check if the request was successful (status code 200)
    if response.status_code == 200:
        # Parse the HTML content of the webpage
        soup = BeautifulSoup(response.text, 'html.parser')

        # Extract text content from the HTML
        text_content = soup.get_text()

        # Tokenize the text using NLTK's word_tokenize
        words = word_tokenize(text_content)

        # Use regular expression to tokenize expressions and numbers
        expressions = regexp_tokenize(text_content, pattern=r'\b(?:[A-Za-z]\.)+|\$?\d+(?:\.\d{1,2})?\b')

        # Display the extracted tokens, expressions, words, and numbers
        print("Tokens:", words)
        print("\nExpressions:", expressions)
        print("\nWords:", [word for word in words if word.isalpha()])
        print("\nNumbers:", [word for word in words if word.isnumeric() or word.replace('.', '').isdigit()])
    else:
        print(f"Failed to retrieve content. Status code: {response.status_code}")

webpage_url = 'https://www.geeksforgeeks.org/'
extract_content_from_webpage(webpage_url)

pip install requests beautifulsoup4 nltk

import requests
from bs4 import BeautifulSoup
from nltk import FreqDist, word_tokenize
import nltk
nltk.download('punkt')

def get_webpage_content(url):
    # Send an HTTP request to the URL
    response = requests.get(url)

    # Check if the request was successful (status code 200)
    if response.status_code == 200:
        # Parse the HTML content of the webpage
        soup = BeautifulSoup(response.text, 'html.parser')

        # Extract text content from the HTML
        text_content = soup.get_text()

        return text_content
    else:
        print(f"Failed to retrieve content. Status code: {response.status_code}")
        return None

def display_word_frequencies(content):
    if content:
        # Tokenize the text using NLTK's word_tokenize
        words = word_tokenize(content)

        # Calculate the frequency distribution of words
        freq_dist = FreqDist(words)

        # Display the word frequency
        print("Word\t\tFrequency")
        print("------------------------")
        for word, frequency in freq_dist.items():
            print(f"{word}\t\t{frequency}")

webpage_url = 'https://www.geeksforgeeks.org/'
webpage_content = get_webpage_content(webpage_url)

if webpage_content:
    display_word_frequencies(webpage_content)

pip install matplotlib

import requests
from bs4 import BeautifulSoup
from nltk import FreqDist, word_tokenize
import nltk
import matplotlib.pyplot as plt

nltk.download('punkt')

def get_webpage_content(url):
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        text_content = soup.get_text()
        return text_content
    else:
        print(f"Failed to retrieve content. Status code: {response.status_code}")
        return None

def display_word_frequencies(content):
    if content:
        words = word_tokenize(content)
        freq_dist = FreqDist(words)

        # Display the word frequency
        print("Word\t\tFrequency")
        print("------------------------")
        for word, frequency in freq_dist.items():
            print(f"{word}\t\t{frequency}")

        # Plot the word frequencies
        plt.figure(figsize=(10, 5))
        freq_dist.plot(30, cumulative=False)
        plt.title('Word Frequency Distribution')
        plt.xlabel('Words')
        plt.ylabel('Frequency')
        plt.show()

webpage_url = 'https://www.geeksforgeeks.org/'
webpage_content = get_webpage_content(webpage_url)

if webpage_content:
    display_word_frequencies(webpage_content)